02:08:21,490 graphrag.index.cli INFO Logging enabled at D:\IdeaProjects\graphrag\graph-rag\output\20240911-010710\reports\indexing-engine.log
02:08:21,495 graphrag.index.cli INFO Starting pipeline run for: 20240911-010710, dryrun=False
02:08:21,496 graphrag.index.cli INFO Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "openai_chat",
        "model": "qwen2-7b-instruct-q5_k_m",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "request_timeout": 600.0,
        "api_base": "http://localhost:11434/v1",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 10
    },
    "async_mode": "threaded",
    "root_dir": "D:\\IdeaProjects\\graphrag\\graph-rag",
    "reporting": {
        "type": "file",
        "base_dir": "D:\\IdeaProjects\\graphrag\\graph-rag\\output\\20240911-010710\\reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "D:\\IdeaProjects\\graphrag\\graph-rag\\output\\20240911-010710\\artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_embedding",
            "model": "nomic-embed-text",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "http://localhost:11434/api",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 10
        },
        "async_mode": "threaded",
        "batch_size": 1,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 300,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "qwen2-7b-instruct-q5_k_m",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 600.0,
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 10
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "qwen2-7b-instruct-q5_k_m",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 600.0,
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 10
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "qwen2-7b-instruct-q5_k_m",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 600.0,
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 10
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "qwen2-7b-instruct-q5_k_m",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 600.0,
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 10
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
02:08:21,498 graphrag.index.create_pipeline_config INFO skipping workflows 
02:08:21,499 graphrag.index.run.run INFO Running pipeline
02:08:21,499 graphrag.index.storage.file_pipeline_storage INFO Creating file storage at D:\IdeaProjects\graphrag\graph-rag\output\20240911-010710\artifacts
02:08:21,500 graphrag.index.input.load_input INFO loading input from root_dir=input
02:08:21,500 graphrag.index.input.load_input INFO using file storage for input
02:08:21,502 graphrag.index.storage.file_pipeline_storage INFO search D:\IdeaProjects\graphrag\graph-rag\input for files matching .*\.txt$
02:08:21,503 graphrag.index.input.text INFO found text files from input, found [('8家消费公司拿到新钱;霸王茶姬高薪招香港店长;一季度快消品平均售价同比降1.5%｜创投大视野.txt', {})]
02:08:21,507 graphrag.index.input.text INFO Found 1 files, loading 1
02:08:21,511 graphrag.index.workflows.load INFO Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents']
02:08:21,511 graphrag.index.run.run INFO Final # of rows loaded: 1
02:08:21,688 graphrag.index.run.workflow INFO dependencies for create_base_text_units: []
02:08:21,696 datashaper.workflow.workflow INFO executing verb orderby
02:08:21,702 datashaper.workflow.workflow INFO executing verb zip
02:08:21,708 datashaper.workflow.workflow INFO executing verb aggregate_override
02:08:21,717 datashaper.workflow.workflow INFO executing verb chunk
02:08:21,986 datashaper.workflow.workflow INFO executing verb select
02:08:21,992 datashaper.workflow.workflow INFO executing verb unroll
02:08:22,2 datashaper.workflow.workflow INFO executing verb rename
02:08:22,9 datashaper.workflow.workflow INFO executing verb genid
02:08:22,19 datashaper.workflow.workflow INFO executing verb unzip
02:08:22,28 datashaper.workflow.workflow INFO executing verb copy
02:08:22,37 datashaper.workflow.workflow INFO executing verb filter
02:08:22,55 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_text_units.parquet
02:08:22,337 graphrag.index.run.workflow INFO dependencies for create_base_extracted_entities: ['create_base_text_units']
02:08:22,338 graphrag.utils.storage INFO read table from storage: create_base_text_units.parquet
02:08:22,369 datashaper.workflow.workflow INFO executing verb entity_extract
02:08:22,376 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=http://localhost:11434/v1
02:08:22,423 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for qwen2-7b-instruct-q5_k_m: TPM=0, RPM=0
02:08:22,423 graphrag.index.llm.load_llm INFO create concurrency limiter for qwen2-7b-instruct-q5_k_m: 25
02:08:39,637 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:08:39,644 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 17.17199999999957. input_tokens=2074, output_tokens=607
02:08:42,991 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:08:42,993 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 20.54700000000048. input_tokens=2074, output_tokens=188
02:08:59,690 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:08:59,693 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 37.25. input_tokens=2073, output_tokens=1008
02:09:12,252 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:09:12,255 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 49.82799999999952. input_tokens=2074, output_tokens=619
02:09:21,804 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:09:21,808 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 59.32800000000043. input_tokens=2075, output_tokens=570
02:09:32,953 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:09:32,957 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 70.4380000000001. input_tokens=2073, output_tokens=582
02:09:37,986 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:09:37,987 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 75.48399999999947. input_tokens=2075, output_tokens=314
02:09:56,476 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:09:56,478 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 94.01599999999962. input_tokens=2073, output_tokens=985
02:10:18,318 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:10:18,321 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 115.85999999999967. input_tokens=2074, output_tokens=1147
02:10:26,364 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:10:26,367 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 123.92200000000048. input_tokens=2074, output_tokens=454
02:10:38,831 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:10:38,834 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 119.1869999999999. input_tokens=34, output_tokens=634
02:10:53,185 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:10:53,189 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 130.1869999999999. input_tokens=34, output_tokens=886
02:11:02,343 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:11:02,347 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 122.64000000000033. input_tokens=34, output_tokens=531
02:11:04,609 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:11:04,611 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 112.34400000000005. input_tokens=34, output_tokens=87
02:11:14,189 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:11:14,191 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 112.39099999999962. input_tokens=34, output_tokens=570
02:11:28,654 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:11:28,660 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 115.6880000000001. input_tokens=34, output_tokens=644
02:13:22,10 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:13:22,14 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 224.01499999999942. input_tokens=34, output_tokens=6480
02:13:33,299 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:13:33,303 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 216.82800000000043. input_tokens=34, output_tokens=521
02:13:37,245 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:13:37,247 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 198.92200000000048. input_tokens=34, output_tokens=172
02:13:43,103 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:13:43,104 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 196.73399999999947. input_tokens=34, output_tokens=311
02:14:01,178 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:14:01,182 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 202.32800000000043. input_tokens=2074, output_tokens=1022
02:14:15,595 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:14:15,599 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 202.39099999999962. input_tokens=2074, output_tokens=676
02:14:25,213 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:14:25,216 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 202.84299999999985. input_tokens=2073, output_tokens=483
02:14:39,121 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:14:39,123 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 214.46900000000005. input_tokens=2074, output_tokens=739
02:14:48,156 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:14:48,159 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 213.9380000000001. input_tokens=2075, output_tokens=473
02:14:59,430 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:14:59,434 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 210.75. input_tokens=2073, output_tokens=590
02:15:12,220 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:15:12,222 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 110.1869999999999. input_tokens=2074, output_tokens=712
02:15:27,74 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:15:27,77 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 113.73499999999967. input_tokens=2074, output_tokens=794
02:15:40,671 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:15:40,674 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 123.39099999999962. input_tokens=2074, output_tokens=641
02:15:47,989 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:15:47,992 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 124.875. input_tokens=2074, output_tokens=409
02:15:51,269 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:15:51,270 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 110.09400000000005. input_tokens=34, output_tokens=153
02:17:45,400 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:17:45,406 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 209.79700000000048. input_tokens=34, output_tokens=6110
02:17:48,692 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:17:48,693 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 203.48499999999967. input_tokens=34, output_tokens=103
02:18:25,77 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:18:25,80 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 225.95299999999952. input_tokens=34, output_tokens=1869
02:18:34,240 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:18:34,243 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 226.07800000000043. input_tokens=34, output_tokens=471
02:18:37,696 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:18:37,698 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 218.26599999999962. input_tokens=34, output_tokens=161
02:18:50,435 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:18:50,437 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 218.20300000000043. input_tokens=34, output_tokens=712
02:18:53,12 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:18:53,15 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 205.92199999999957. input_tokens=34, output_tokens=111
02:18:58,248 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:18:58,251 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 197.5630000000001. input_tokens=34, output_tokens=238
02:19:00,405 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:19:00,407 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 192.40599999999995. input_tokens=34, output_tokens=98
02:19:15,78 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:19:15,82 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 203.78099999999995. input_tokens=2073, output_tokens=753
02:19:22,799 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:19:22,801 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 97.35900000000038. input_tokens=2073, output_tokens=375
02:19:39,494 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:19:39,498 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 110.78200000000015. input_tokens=2073, output_tokens=861
02:19:46,552 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:19:46,555 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 81.45300000000043. input_tokens=2072, output_tokens=375
02:19:53,702 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:19:53,705 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 79.4380000000001. input_tokens=2073, output_tokens=358
02:20:05,887 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:20:05,890 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 88.15599999999995. input_tokens=2073, output_tokens=647
02:20:22,693 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:20:22,698 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 92.25. input_tokens=2075, output_tokens=898
02:20:27,47 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:20:27,50 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "Process" with 0 retries took 94.0. input_tokens=1967, output_tokens=206
02:20:35,563 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:20:35,567 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 80.48499999999967. input_tokens=34, output_tokens=422
02:20:38,58 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:20:38,59 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 75.25. input_tokens=34, output_tokens=104
02:20:45,560 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:20:45,562 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 66.0619999999999. input_tokens=34, output_tokens=351
02:22:36,659 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:22:36,669 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 170.10999999999967. input_tokens=34, output_tokens=5979
02:22:40,372 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:22:40,374 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 166.65700000000015. input_tokens=34, output_tokens=118
02:22:43,622 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:22:43,625 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 157.71900000000005. input_tokens=34, output_tokens=142
02:22:50,72 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:22:50,75 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 147.375. input_tokens=34, output_tokens=319
02:22:54,340 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:22:54,343 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "extract-continuation-0" with 0 retries took 147.28099999999995. input_tokens=34, output_tokens=212
02:22:54,366 datashaper.workflow.workflow INFO executing verb merge_graphs
02:22:54,420 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_extracted_entities.parquet
02:22:54,638 graphrag.index.run.workflow INFO dependencies for create_summarized_entities: ['create_base_extracted_entities']
02:22:54,639 graphrag.utils.storage INFO read table from storage: create_base_extracted_entities.parquet
02:22:54,674 datashaper.workflow.workflow INFO executing verb summarize_descriptions
02:22:56,694 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:22:56,695 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 1.9849999999996726. input_tokens=166, output_tokens=73
02:22:59,565 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:22:59,568 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 4.844000000000051. input_tokens=222, output_tokens=102
02:23:01,696 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:23:01,699 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 6.95299999999952. input_tokens=187, output_tokens=161
02:23:02,831 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:23:02,834 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 8.092999999999847. input_tokens=191, output_tokens=41
02:23:03,246 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:23:03,249 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 8.516000000000531. input_tokens=160, output_tokens=23
02:23:05,390 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:23:05,391 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 10.639999999999418. input_tokens=226, output_tokens=151
02:23:07,432 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:23:07,435 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 12.70300000000043. input_tokens=217, output_tokens=119
02:23:10,477 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:23:10,480 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 15.765999999999622. input_tokens=349, output_tokens=193
02:23:11,811 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:23:11,814 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 17.061999999999898. input_tokens=167, output_tokens=53
02:23:18,590 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:23:18,591 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 23.85900000000038. input_tokens=228, output_tokens=250
02:23:20,906 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:23:20,909 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 24.188000000000102. input_tokens=218, output_tokens=176
02:23:23,700 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:23:23,703 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 24.09400000000005. input_tokens=273, output_tokens=223
02:23:25,362 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:23:25,363 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 23.64100000000053. input_tokens=191, output_tokens=59
02:23:26,474 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:23:26,476 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 23.625. input_tokens=190, output_tokens=69
02:23:27,347 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:23:27,350 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 24.07799999999952. input_tokens=189, output_tokens=54
02:23:29,86 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:23:29,88 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 23.686999999999898. input_tokens=185, output_tokens=63
02:23:31,124 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:23:31,127 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 23.657000000000153. input_tokens=193, output_tokens=66
02:23:31,661 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:23:31,663 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 21.157000000000153. input_tokens=187, output_tokens=36
02:23:33,719 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:23:33,721 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 21.85900000000038. input_tokens=335, output_tokens=166
02:23:35,590 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:23:35,593 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 16.98400000000038. input_tokens=229, output_tokens=147
02:23:39,907 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:23:39,910 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 18.953999999999724. input_tokens=256, output_tokens=183
02:23:42,825 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:23:42,828 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 19.09400000000005. input_tokens=188, output_tokens=114
02:23:45,10 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:23:45,12 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 19.60899999999947. input_tokens=179, output_tokens=160
02:23:47,657 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:23:47,659 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 21.15599999999995. input_tokens=222, output_tokens=190
02:23:51,217 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:23:51,218 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 23.82800000000043. input_tokens=230, output_tokens=132
02:23:54,106 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:23:54,109 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 25.0. input_tokens=324, output_tokens=203
02:23:56,74 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:23:56,77 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 24.92199999999957. input_tokens=235, output_tokens=110
02:23:58,174 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:23:58,177 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 26.5. input_tokens=269, output_tokens=157
02:23:58,979 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:23:58,981 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 25.23399999999947. input_tokens=206, output_tokens=64
02:24:00,906 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:24:00,907 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 25.28099999999995. input_tokens=231, output_tokens=66
02:24:03,339 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:24:03,342 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 23.40599999999995. input_tokens=227, output_tokens=185
02:24:10,620 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:24:10,623 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 27.76600000000053. input_tokens=210, output_tokens=262
02:24:13,157 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:24:13,160 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 28.125. input_tokens=209, output_tokens=93
02:24:13,969 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:24:13,971 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 26.28099999999995. input_tokens=189, output_tokens=53
02:24:14,925 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:24:14,928 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 23.70300000000043. input_tokens=254, output_tokens=62
02:24:17,847 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:24:17,850 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 23.73399999999947. input_tokens=239, output_tokens=199
02:24:21,886 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:24:21,887 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 25.764999999999418. input_tokens=235, output_tokens=142
02:24:22,941 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:24:22,943 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 24.75. input_tokens=189, output_tokens=57
02:24:25,415 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:24:25,416 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 26.359999999999673. input_tokens=224, output_tokens=213
02:24:26,391 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:24:26,394 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 25.45299999999952. input_tokens=194, output_tokens=68
02:24:29,22 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:24:29,24 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 25.65599999999995. input_tokens=199, output_tokens=187
02:24:34,188 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:24:34,189 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 23.53099999999995. input_tokens=203, output_tokens=174
02:24:37,148 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:24:37,151 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 23.96900000000005. input_tokens=215, output_tokens=103
02:24:39,724 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:24:39,727 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 25.73399999999947. input_tokens=212, output_tokens=95
02:24:43,132 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:24:43,135 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 28.186999999999898. input_tokens=211, output_tokens=129
02:24:45,845 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:24:45,847 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 27.967999999999847. input_tokens=225, output_tokens=98
02:24:48,569 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:24:48,572 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 26.67199999999957. input_tokens=238, output_tokens=109
02:24:50,894 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:24:50,895 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 27.938000000000102. input_tokens=227, output_tokens=96
02:25:00,574 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:25:00,585 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 35.14000000000033. input_tokens=241, output_tokens=358
02:25:03,344 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:25:03,345 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "summarize" with 0 retries took 36.90599999999995. input_tokens=219, output_tokens=111
02:25:03,402 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_summarized_entities.parquet
02:25:03,596 graphrag.index.run.workflow INFO dependencies for create_base_entity_graph: ['create_summarized_entities']
02:25:03,597 graphrag.utils.storage INFO read table from storage: create_summarized_entities.parquet
02:25:03,627 datashaper.workflow.workflow INFO executing verb cluster_graph
02:25:03,758 datashaper.workflow.workflow INFO executing verb select
02:25:03,762 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_entity_graph.parquet
02:25:03,962 graphrag.index.run.workflow INFO dependencies for create_final_entities: ['create_base_entity_graph']
02:25:03,962 graphrag.utils.storage INFO read table from storage: create_base_entity_graph.parquet
02:25:03,994 datashaper.workflow.workflow INFO executing verb unpack_graph
02:25:04,29 datashaper.workflow.workflow INFO executing verb rename
02:25:04,43 datashaper.workflow.workflow INFO executing verb select
02:25:04,58 datashaper.workflow.workflow INFO executing verb dedupe
02:25:04,73 datashaper.workflow.workflow INFO executing verb rename
02:25:04,89 datashaper.workflow.workflow INFO executing verb filter
02:25:04,142 datashaper.workflow.workflow INFO executing verb text_split
02:25:04,166 datashaper.workflow.workflow INFO executing verb drop
02:25:04,183 datashaper.workflow.workflow INFO executing verb merge
02:25:04,326 datashaper.workflow.workflow INFO executing verb text_embed
02:25:04,328 graphrag.llm.openai.create_openai_client INFO Creating OpenAI client base_url=http://localhost:11434/api
02:25:04,390 graphrag.index.llm.load_llm INFO create TPM/RPM limiter for nomic-embed-text: TPM=0, RPM=0
02:25:04,390 graphrag.index.llm.load_llm INFO create concurrency limiter for nomic-embed-text: 25
02:25:04,416 graphrag.index.verbs.text.embed.strategies.openai INFO embedding 306 inputs via 306 snippets using 306 batches. max_batch_size=1, max_tokens=8191
02:25:08,761 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:08,763 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 4.342999999999847. input_tokens=202, output_tokens=0
02:25:08,794 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:08,795 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=19, output_tokens=0
02:25:08,824 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:08,825 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=76, output_tokens=0
02:25:08,882 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:08,883 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.06199999999989814. input_tokens=44, output_tokens=0
02:25:08,911 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:08,912 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=36, output_tokens=0
02:25:08,955 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:08,956 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=124, output_tokens=0
02:25:08,997 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:08,999 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=28, output_tokens=0
02:25:09,34 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:09,35 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.04699999999957072. input_tokens=10, output_tokens=0
02:25:09,62 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:09,62 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.015000000000327418. input_tokens=12, output_tokens=0
02:25:09,91 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:09,91 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=56, output_tokens=0
02:25:09,152 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:09,153 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=36, output_tokens=0
02:25:09,182 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:09,182 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=62, output_tokens=0
02:25:09,210 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:09,211 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=114, output_tokens=0
02:25:09,245 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:09,247 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=260, output_tokens=0
02:25:09,276 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:09,277 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=175, output_tokens=0
02:25:09,307 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:09,307 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=14, output_tokens=0
02:25:09,334 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:09,336 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=83, output_tokens=0
02:25:09,364 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:09,365 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=24, output_tokens=0
02:25:09,394 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:09,394 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=60, output_tokens=0
02:25:09,426 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:09,427 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=12, output_tokens=0
02:25:09,484 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:09,484 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=158, output_tokens=0
02:25:09,511 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:09,512 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=38, output_tokens=0
02:25:09,538 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:09,539 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=38, output_tokens=0
02:25:09,566 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:09,566 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=47, output_tokens=0
02:25:09,594 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:09,594 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.015000000000327418. input_tokens=53, output_tokens=0
02:25:09,628 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:09,628 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.04699999999957072. input_tokens=39, output_tokens=0
02:25:09,685 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:09,685 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=25, output_tokens=0
02:25:09,721 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:09,722 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=25, output_tokens=0
02:25:09,749 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:09,750 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.016000000000531145. input_tokens=29, output_tokens=0
02:25:09,777 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:09,779 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=12, output_tokens=0
02:25:09,831 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:09,832 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=59, output_tokens=0
02:25:09,870 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:09,870 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=34, output_tokens=0
02:25:09,925 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:09,929 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.06199999999989814. input_tokens=27, output_tokens=0
02:25:09,964 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:09,966 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=182, output_tokens=0
02:25:10,25 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:10,27 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.04700000000048021. input_tokens=23, output_tokens=0
02:25:10,55 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:10,56 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=230, output_tokens=0
02:25:10,92 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:10,94 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=64, output_tokens=0
02:25:10,122 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:10,124 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=74, output_tokens=0
02:25:10,151 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:10,153 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=59, output_tokens=0
02:25:10,181 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:10,182 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=69, output_tokens=0
02:25:10,241 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:10,242 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.04700000000048021. input_tokens=77, output_tokens=0
02:25:10,269 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:10,270 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=36, output_tokens=0
02:25:10,298 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:10,300 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=46, output_tokens=0
02:25:10,328 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:10,329 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.01599999999962165. input_tokens=34, output_tokens=0
02:25:10,380 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:10,381 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=20, output_tokens=0
02:25:10,411 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:10,411 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=23, output_tokens=0
02:25:10,438 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:10,439 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.015000000000327418. input_tokens=24, output_tokens=0
02:25:10,473 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:10,473 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=43, output_tokens=0
02:25:10,501 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:10,502 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.016000000000531145. input_tokens=57, output_tokens=0
02:25:10,527 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:10,528 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=13, output_tokens=0
02:25:10,584 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:10,585 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=101, output_tokens=0
02:25:10,612 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:10,614 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=13, output_tokens=0
02:25:10,649 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:10,649 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=14, output_tokens=0
02:25:10,684 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:10,685 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=10, output_tokens=0
02:25:10,711 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:10,711 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=16, output_tokens=0
02:25:10,771 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:10,772 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.04700000000048021. input_tokens=21, output_tokens=0
02:25:10,804 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:10,806 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=28, output_tokens=0
02:25:10,835 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:10,835 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=12, output_tokens=0
02:25:10,861 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:10,862 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.01599999999962165. input_tokens=18, output_tokens=0
02:25:10,909 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:10,909 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.016000000000531145. input_tokens=91, output_tokens=0
02:25:10,958 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:10,959 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.046000000000276486. input_tokens=172, output_tokens=0
02:25:10,987 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:10,987 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.01599999999962165. input_tokens=51, output_tokens=0
02:25:11,43 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:11,44 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=5, output_tokens=0
02:25:11,73 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:11,73 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=57, output_tokens=0
02:25:11,104 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:11,105 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=5, output_tokens=0
02:25:11,161 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:11,163 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.04699999999957072. input_tokens=152, output_tokens=0
02:25:11,198 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:11,199 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=39, output_tokens=0
02:25:11,228 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:11,230 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=46, output_tokens=0
02:25:11,264 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:11,265 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=41, output_tokens=0
02:25:11,314 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:11,315 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.015000000000327418. input_tokens=42, output_tokens=0
02:25:11,344 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:11,345 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.015000000000327418. input_tokens=45, output_tokens=0
02:25:11,378 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:11,379 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.04699999999957072. input_tokens=47, output_tokens=0
02:25:11,432 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:11,433 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=41, output_tokens=0
02:25:11,460 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:11,461 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=29, output_tokens=0
02:25:11,488 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:11,489 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=45, output_tokens=0
02:25:11,547 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:11,548 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=46, output_tokens=0
02:25:11,575 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:11,576 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=55, output_tokens=0
02:25:11,610 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:11,610 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=30, output_tokens=0
02:25:11,673 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:11,673 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=38, output_tokens=0
02:25:11,713 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:11,715 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=32, output_tokens=0
02:25:11,744 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:11,744 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=59, output_tokens=0
02:25:11,809 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:11,811 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.04700000000048021. input_tokens=188, output_tokens=0
02:25:11,852 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:11,853 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.04699999999957072. input_tokens=55, output_tokens=0
02:25:11,912 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:11,913 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=75, output_tokens=0
02:25:11,947 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:11,949 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=30, output_tokens=0
02:25:11,997 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:11,998 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.04700000000048021. input_tokens=52, output_tokens=0
02:25:12,56 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:12,57 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=43, output_tokens=0
02:25:12,94 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:12,96 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=116, output_tokens=0
02:25:12,155 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:12,156 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=43, output_tokens=0
02:25:12,184 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:12,185 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=21, output_tokens=0
02:25:12,215 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:12,217 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=42, output_tokens=0
02:25:12,263 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:12,264 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.04699999999957072. input_tokens=36, output_tokens=0
02:25:12,312 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:12,313 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.04700000000048021. input_tokens=18, output_tokens=0
02:25:12,371 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:12,372 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=18, output_tokens=0
02:25:12,401 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:12,403 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=7, output_tokens=0
02:25:12,432 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:12,434 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=13, output_tokens=0
02:25:12,462 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:12,464 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=6, output_tokens=0
02:25:12,494 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:12,495 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=7, output_tokens=0
02:25:12,553 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:12,554 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.04700000000048021. input_tokens=9, output_tokens=0
02:25:12,581 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:12,583 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=38, output_tokens=0
02:25:12,618 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:12,619 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=36, output_tokens=0
02:25:12,658 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:12,659 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=29, output_tokens=0
02:25:12,692 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:12,694 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=36, output_tokens=0
02:25:12,763 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:12,763 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=40, output_tokens=0
02:25:12,794 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:12,795 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=35, output_tokens=0
02:25:12,823 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:12,824 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=32, output_tokens=0
02:25:12,859 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:12,860 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=34, output_tokens=0
02:25:12,912 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:12,914 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=31, output_tokens=0
02:25:12,960 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:12,961 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.046000000000276486. input_tokens=35, output_tokens=0
02:25:12,993 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:12,994 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=32, output_tokens=0
02:25:13,28 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:13,29 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=35, output_tokens=0
02:25:13,79 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:13,81 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.04699999999957072. input_tokens=10, output_tokens=0
02:25:13,115 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:13,116 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=32, output_tokens=0
02:25:13,176 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:13,177 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=29, output_tokens=0
02:25:13,204 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:13,205 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.01599999999962165. input_tokens=29, output_tokens=0
02:25:13,235 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:13,237 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.01599999999962165. input_tokens=34, output_tokens=0
02:25:13,266 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:13,268 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.014999999999417923. input_tokens=32, output_tokens=0
02:25:13,298 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:13,298 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.01599999999962165. input_tokens=29, output_tokens=0
02:25:13,358 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:13,359 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=34, output_tokens=0
02:25:13,388 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:13,388 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=28, output_tokens=0
02:25:13,419 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:13,421 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=36, output_tokens=0
02:25:13,449 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:13,450 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=30, output_tokens=0
02:25:13,500 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:13,502 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.04700000000048021. input_tokens=30, output_tokens=0
02:25:13,552 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:13,552 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=30, output_tokens=0
02:25:13,583 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:13,583 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=40, output_tokens=0
02:25:13,613 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:13,614 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=38, output_tokens=0
02:25:13,642 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:13,644 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.014999999999417923. input_tokens=33, output_tokens=0
02:25:13,671 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:13,672 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.01599999999962165. input_tokens=29, output_tokens=0
02:25:13,723 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:13,725 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=30, output_tokens=0
02:25:13,750 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:13,750 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.016000000000531145. input_tokens=29, output_tokens=0
02:25:13,777 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:13,777 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=38, output_tokens=0
02:25:13,802 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:13,802 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=33, output_tokens=0
02:25:13,850 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:13,851 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=31, output_tokens=0
02:25:13,879 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:13,881 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=29, output_tokens=0
02:25:13,916 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:13,918 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=34, output_tokens=0
02:25:13,947 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:13,948 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=36, output_tokens=0
02:25:13,972 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:13,973 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=33, output_tokens=0
02:25:14,0 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:14,2 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.016000000000531145. input_tokens=34, output_tokens=0
02:25:14,77 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:14,79 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.04699999999957072. input_tokens=32, output_tokens=0
02:25:14,113 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:14,114 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.04700000000048021. input_tokens=30, output_tokens=0
02:25:14,154 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:14,155 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=35, output_tokens=0
02:25:14,208 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:14,209 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.046000000000276486. input_tokens=38, output_tokens=0
02:25:14,254 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:14,254 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.04699999999957072. input_tokens=35, output_tokens=0
02:25:14,319 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:14,321 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.04699999999957072. input_tokens=37, output_tokens=0
02:25:14,355 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:14,357 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=39, output_tokens=0
02:25:14,385 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:14,385 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=30, output_tokens=0
02:25:14,418 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:14,418 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=35, output_tokens=0
02:25:14,476 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:14,477 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=40, output_tokens=0
02:25:14,510 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:14,512 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=36, output_tokens=0
02:25:14,541 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:14,543 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=42, output_tokens=0
02:25:14,571 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:14,573 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=33, output_tokens=0
02:25:14,638 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:14,640 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=40, output_tokens=0
02:25:14,670 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:14,672 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.01599999999962165. input_tokens=41, output_tokens=0
02:25:14,704 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:14,706 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=166, output_tokens=0
02:25:14,758 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:14,759 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=196, output_tokens=0
02:25:14,789 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:14,790 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=41, output_tokens=0
02:25:14,824 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:14,826 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=23, output_tokens=0
02:25:14,899 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:14,899 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=30, output_tokens=0
02:25:14,941 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:14,941 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.04699999999957072. input_tokens=27, output_tokens=0
02:25:14,968 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:14,969 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.015000000000327418. input_tokens=6, output_tokens=0
02:25:15,12 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:15,14 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.04699999999957072. input_tokens=81, output_tokens=0
02:25:15,68 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:15,69 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=136, output_tokens=0
02:25:15,129 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:15,131 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.04699999999957072. input_tokens=47, output_tokens=0
02:25:15,166 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:15,167 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=46, output_tokens=0
02:25:15,195 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:15,196 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=44, output_tokens=0
02:25:15,253 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:15,254 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=8, output_tokens=0
02:25:15,283 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:15,284 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.016000000000531145. input_tokens=57, output_tokens=0
02:25:15,322 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:15,323 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=43, output_tokens=0
02:25:15,353 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:15,356 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=35, output_tokens=0
02:25:15,388 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:15,389 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=21, output_tokens=0
02:25:15,416 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:15,416 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=25, output_tokens=0
02:25:15,472 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:15,474 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=4, output_tokens=0
02:25:15,500 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:15,502 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.016000000000531145. input_tokens=4, output_tokens=0
02:25:15,534 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:15,535 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=41, output_tokens=0
02:25:15,563 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:15,564 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.015000000000327418. input_tokens=28, output_tokens=0
02:25:15,596 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:15,598 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.04699999999957072. input_tokens=45, output_tokens=0
02:25:15,650 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:15,651 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=24, output_tokens=0
02:25:15,684 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:15,684 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=207, output_tokens=0
02:25:15,712 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:15,714 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=28, output_tokens=0
02:25:15,753 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:15,755 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.04699999999957072. input_tokens=164, output_tokens=0
02:25:15,790 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:15,791 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=118, output_tokens=0
02:25:15,853 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:15,853 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=50, output_tokens=0
02:25:15,881 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:15,883 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=34, output_tokens=0
02:25:15,910 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:15,910 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=80, output_tokens=0
02:25:15,936 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:15,936 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.015000000000327418. input_tokens=36, output_tokens=0
02:25:15,964 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:15,964 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=68, output_tokens=0
02:25:16,26 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:16,26 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=189, output_tokens=0
02:25:16,58 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:16,59 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=101, output_tokens=0
02:25:16,94 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:16,95 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=275, output_tokens=0
02:25:16,157 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:16,158 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=48, output_tokens=0
02:25:16,185 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:16,186 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=40, output_tokens=0
02:25:16,252 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:16,253 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.04699999999957072. input_tokens=48, output_tokens=0
02:25:16,280 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:16,281 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.016000000000531145. input_tokens=38, output_tokens=0
02:25:16,308 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:16,309 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=35, output_tokens=0
02:25:16,334 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:16,335 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=10, output_tokens=0
02:25:16,363 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:16,364 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=42, output_tokens=0
02:25:16,427 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:16,428 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=58, output_tokens=0
02:25:16,456 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:16,456 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.01599999999962165. input_tokens=35, output_tokens=0
02:25:16,483 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:16,484 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.01599999999962165. input_tokens=34, output_tokens=0
02:25:16,508 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:16,509 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=19, output_tokens=0
02:25:16,535 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:16,535 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=76, output_tokens=0
02:25:16,583 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:16,583 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=29, output_tokens=0
02:25:16,611 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:16,612 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.01599999999962165. input_tokens=5, output_tokens=0
02:25:16,640 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:16,642 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.014999999999417923. input_tokens=50, output_tokens=0
02:25:16,675 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:16,675 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=35, output_tokens=0
02:25:16,701 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:16,702 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.01599999999962165. input_tokens=204, output_tokens=0
02:25:16,764 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:16,765 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=67, output_tokens=0
02:25:16,791 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:16,791 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=24, output_tokens=0
02:25:16,820 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:16,820 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=59, output_tokens=0
02:25:16,879 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:16,880 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.04699999999957072. input_tokens=19, output_tokens=0
02:25:16,907 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:16,907 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.016000000000531145. input_tokens=23, output_tokens=0
02:25:16,937 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:16,939 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.015000000000327418. input_tokens=20, output_tokens=0
02:25:16,971 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:16,972 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=34, output_tokens=0
02:25:16,999 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:16,999 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.016000000000531145. input_tokens=63, output_tokens=0
02:25:17,28 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:17,29 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=20, output_tokens=0
02:25:17,55 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:17,56 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=22, output_tokens=0
02:25:17,113 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:17,114 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.04700000000048021. input_tokens=150, output_tokens=0
02:25:17,173 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:17,175 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.04699999999957072. input_tokens=33, output_tokens=0
02:25:17,276 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:17,278 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.06300000000010186. input_tokens=22, output_tokens=0
02:25:17,306 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:17,308 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=43, output_tokens=0
02:25:17,343 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:17,344 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=40, output_tokens=0
02:25:17,394 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:17,394 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=5, output_tokens=0
02:25:17,421 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:17,422 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.01599999999962165. input_tokens=41, output_tokens=0
02:25:17,450 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:17,450 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=38, output_tokens=0
02:25:17,476 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:17,477 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=20, output_tokens=0
02:25:17,503 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:17,504 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=80, output_tokens=0
02:25:17,564 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:17,565 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.015000000000327418. input_tokens=17, output_tokens=0
02:25:17,593 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:17,593 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.015000000000327418. input_tokens=38, output_tokens=0
02:25:17,621 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:17,621 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=42, output_tokens=0
02:25:17,676 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:17,678 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.04700000000048021. input_tokens=56, output_tokens=0
02:25:17,706 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:17,707 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=31, output_tokens=0
02:25:17,733 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:17,735 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.01599999999962165. input_tokens=6, output_tokens=0
02:25:17,763 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:17,764 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=62, output_tokens=0
02:25:17,789 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:17,791 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=20, output_tokens=0
02:25:17,827 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:17,828 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=66, output_tokens=0
02:25:17,861 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:17,862 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=62, output_tokens=0
02:25:17,920 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:17,920 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.01599999999962165. input_tokens=40, output_tokens=0
02:25:17,958 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:17,959 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.046000000000276486. input_tokens=68, output_tokens=0
02:25:17,985 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:17,986 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.01599999999962165. input_tokens=4, output_tokens=0
02:25:18,43 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:18,44 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=9, output_tokens=0
02:25:18,82 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:18,82 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.046000000000276486. input_tokens=12, output_tokens=0
02:25:18,116 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:18,117 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=8, output_tokens=0
02:25:18,148 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:18,149 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=35, output_tokens=0
02:25:18,191 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:18,192 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.04699999999957072. input_tokens=11, output_tokens=0
02:25:18,236 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:18,237 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=33, output_tokens=0
02:25:18,267 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:18,268 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=5, output_tokens=0
02:25:18,329 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:18,330 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=19, output_tokens=0
02:25:18,361 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:18,362 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.01599999999962165. input_tokens=9, output_tokens=0
02:25:18,391 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:18,391 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.014999999999417923. input_tokens=10, output_tokens=0
02:25:18,454 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:18,456 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=36, output_tokens=0
02:25:18,489 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:18,491 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=17, output_tokens=0
02:25:18,522 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:18,523 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=39, output_tokens=0
02:25:18,551 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:18,551 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=12, output_tokens=0
02:25:18,582 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:18,583 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=28, output_tokens=0
02:25:18,614 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:18,616 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=37, output_tokens=0
02:25:18,646 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:18,647 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=12, output_tokens=0
02:25:18,706 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:18,707 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.046000000000276486. input_tokens=11, output_tokens=0
02:25:18,737 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:18,738 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=24, output_tokens=0
02:25:18,765 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:18,766 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.014999999999417923. input_tokens=12, output_tokens=0
02:25:18,840 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:18,840 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.046000000000276486. input_tokens=39, output_tokens=0
02:25:18,872 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:18,874 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=14, output_tokens=0
02:25:18,921 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:18,922 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.01599999999962165. input_tokens=39, output_tokens=0
02:25:18,949 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:18,950 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=14, output_tokens=0
02:25:18,981 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:18,981 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=37, output_tokens=0
02:25:19,11 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:19,12 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=13, output_tokens=0
02:25:19,41 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:19,41 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=26, output_tokens=0
02:25:19,100 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:19,100 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=14, output_tokens=0
02:25:19,128 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:19,129 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=38, output_tokens=0
02:25:19,161 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:19,161 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=14, output_tokens=0
02:25:19,189 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:19,190 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.015000000000327418. input_tokens=29, output_tokens=0
02:25:19,249 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:19,251 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.04700000000048021. input_tokens=15, output_tokens=0
02:25:19,310 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:19,311 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=40, output_tokens=0
02:25:19,340 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:19,342 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=17, output_tokens=0
02:25:19,371 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:19,371 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=41, output_tokens=0
02:25:19,443 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:19,445 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.06300000000010186. input_tokens=20, output_tokens=0
02:25:19,479 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:19,479 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=42, output_tokens=0
02:25:19,509 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:19,510 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=15, output_tokens=0
02:25:19,561 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:19,562 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=30, output_tokens=0
02:25:19,591 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:19,592 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=16, output_tokens=0
02:25:19,620 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:19,621 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=21, output_tokens=0
02:25:19,654 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:19,655 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=43, output_tokens=0
02:25:19,688 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:19,690 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=18, output_tokens=0
02:25:19,720 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:19,720 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.015000000000327418. input_tokens=31, output_tokens=0
02:25:19,749 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:19,749 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=17, output_tokens=0
02:25:19,807 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:19,809 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=19, output_tokens=0
02:25:19,840 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:19,841 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=33, output_tokens=0
02:25:19,871 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:19,872 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=40, output_tokens=0
02:25:19,927 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:19,928 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=29, output_tokens=0
02:25:19,959 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:19,960 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=37, output_tokens=0
02:25:19,992 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:19,994 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=80, output_tokens=0
02:25:20,24 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:20,25 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=55, output_tokens=0
02:25:20,59 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:20,62 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=222, output_tokens=0
02:25:20,93 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:20,95 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=27, output_tokens=0
02:25:20,128 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:20,128 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.04699999999957072. input_tokens=10, output_tokens=0
02:25:20,202 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:20,203 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.04699999999957072. input_tokens=14, output_tokens=0
02:25:20,252 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:20,253 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.04700000000048021. input_tokens=30, output_tokens=0
02:25:20,292 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:20,293 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=30, output_tokens=0
02:25:20,343 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:20,343 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=26, output_tokens=0
02:25:20,375 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:20,377 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=48, output_tokens=0
02:25:20,413 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:20,414 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=10, output_tokens=0
02:25:20,441 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:20,442 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=8, output_tokens=0
02:25:20,469 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:20,469 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.015000000000327418. input_tokens=21, output_tokens=0
02:25:20,496 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:20,497 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.032000000000152795. input_tokens=8, output_tokens=0
02:25:20,563 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:20,565 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=77, output_tokens=0
02:25:20,595 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:20,597 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=34, output_tokens=0
02:25:20,632 httpx INFO HTTP Request: POST http://127.0.0.1:11434/api/embeddings "HTTP/1.1 200 OK"
02:25:20,633 graphrag.llm.base.rate_limiting_llm INFO perf - llm.embedding "Process" with 0 retries took 0.03099999999994907. input_tokens=71, output_tokens=0
02:25:20,674 datashaper.workflow.workflow INFO executing verb drop
02:25:20,695 datashaper.workflow.workflow INFO executing verb filter
02:25:20,726 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_entities.parquet
02:25:21,33 graphrag.index.run.workflow INFO dependencies for create_final_nodes: ['create_base_entity_graph']
02:25:21,34 graphrag.utils.storage INFO read table from storage: create_base_entity_graph.parquet
02:25:21,76 datashaper.workflow.workflow INFO executing verb layout_graph
02:25:21,203 datashaper.workflow.workflow INFO executing verb unpack_graph
02:25:21,248 datashaper.workflow.workflow INFO executing verb unpack_graph
02:25:21,333 datashaper.workflow.workflow INFO executing verb drop
02:25:21,354 datashaper.workflow.workflow INFO executing verb filter
02:25:21,407 datashaper.workflow.workflow INFO executing verb select
02:25:21,430 datashaper.workflow.workflow INFO executing verb rename
02:25:21,452 datashaper.workflow.workflow INFO executing verb convert
02:25:21,530 datashaper.workflow.workflow INFO executing verb join
02:25:21,563 datashaper.workflow.workflow INFO executing verb rename
02:25:21,568 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_nodes.parquet
02:25:21,815 graphrag.index.run.workflow INFO dependencies for create_final_communities: ['create_base_entity_graph']
02:25:21,816 graphrag.utils.storage INFO read table from storage: create_base_entity_graph.parquet
02:25:21,869 datashaper.workflow.workflow INFO executing verb unpack_graph
02:25:21,916 datashaper.workflow.workflow INFO executing verb unpack_graph
02:25:21,963 datashaper.workflow.workflow INFO executing verb aggregate_override
02:25:21,992 datashaper.workflow.workflow INFO executing verb join
02:25:22,28 datashaper.workflow.workflow INFO executing verb join
02:25:22,69 datashaper.workflow.workflow INFO executing verb concat
02:25:22,96 datashaper.workflow.workflow INFO executing verb filter
02:25:22,166 datashaper.workflow.workflow INFO executing verb aggregate_override
02:25:22,199 datashaper.workflow.workflow INFO executing verb join
02:25:22,236 datashaper.workflow.workflow INFO executing verb filter
02:25:22,301 datashaper.workflow.workflow INFO executing verb fill
02:25:22,331 datashaper.workflow.workflow INFO executing verb merge
02:25:22,418 datashaper.workflow.workflow INFO executing verb copy
02:25:22,448 datashaper.workflow.workflow INFO executing verb select
02:25:22,451 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_communities.parquet
02:25:22,715 graphrag.index.run.workflow INFO dependencies for join_text_units_to_entity_ids: ['create_final_entities']
02:25:22,716 graphrag.utils.storage INFO read table from storage: create_final_entities.parquet
02:25:22,821 datashaper.workflow.workflow INFO executing verb select
02:25:22,854 datashaper.workflow.workflow INFO executing verb unroll
02:25:22,888 datashaper.workflow.workflow INFO executing verb aggregate_override
02:25:22,896 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_entity_ids.parquet
02:25:23,178 graphrag.index.run.workflow INFO dependencies for create_final_relationships: ['create_base_entity_graph', 'create_final_nodes']
02:25:23,179 graphrag.utils.storage INFO read table from storage: create_base_entity_graph.parquet
02:25:23,187 graphrag.utils.storage INFO read table from storage: create_final_nodes.parquet
02:25:23,266 datashaper.workflow.workflow INFO executing verb unpack_graph
02:25:23,322 datashaper.workflow.workflow INFO executing verb filter
02:25:23,401 datashaper.workflow.workflow INFO executing verb rename
02:25:23,499 datashaper.workflow.workflow INFO executing verb filter
02:25:23,625 datashaper.workflow.workflow INFO executing verb drop
02:25:23,663 datashaper.workflow.workflow INFO executing verb compute_edge_combined_degree
02:25:23,705 datashaper.workflow.workflow INFO executing verb convert
02:25:23,779 datashaper.workflow.workflow INFO executing verb convert
02:25:23,783 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_relationships.parquet
02:25:24,66 graphrag.index.run.workflow INFO dependencies for join_text_units_to_relationship_ids: ['create_final_relationships']
02:25:24,67 graphrag.utils.storage INFO read table from storage: create_final_relationships.parquet
02:25:24,151 datashaper.workflow.workflow INFO executing verb select
02:25:24,189 datashaper.workflow.workflow INFO executing verb unroll
02:25:24,230 datashaper.workflow.workflow INFO executing verb aggregate_override
02:25:24,273 datashaper.workflow.workflow INFO executing verb select
02:25:24,277 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table join_text_units_to_relationship_ids.parquet
02:25:24,626 graphrag.index.run.workflow INFO dependencies for create_final_community_reports: ['create_final_relationships', 'create_final_nodes']
02:25:24,627 graphrag.utils.storage INFO read table from storage: create_final_relationships.parquet
02:25:24,635 graphrag.utils.storage INFO read table from storage: create_final_nodes.parquet
02:25:24,724 datashaper.workflow.workflow INFO executing verb prepare_community_reports_nodes
02:25:24,772 datashaper.workflow.workflow INFO executing verb prepare_community_reports_edges
02:25:24,818 datashaper.workflow.workflow INFO executing verb restore_community_hierarchy
02:25:24,864 datashaper.workflow.workflow INFO executing verb prepare_community_reports
02:25:24,865 graphrag.index.verbs.graph.report.prepare_community_reports INFO Number of nodes at level=0 => 306
02:25:24,958 datashaper.workflow.workflow INFO executing verb create_community_reports
02:25:50,863 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:25:50,868 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 25.875. input_tokens=4498, output_tokens=1368
02:26:06,559 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:26:06,561 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 41.59400000000005. input_tokens=2285, output_tokens=842
02:26:23,184 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:26:23,188 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 58.20300000000043. input_tokens=2769, output_tokens=581
02:26:35,632 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:26:35,636 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 70.63999999999942. input_tokens=2306, output_tokens=735
02:26:48,977 httpx INFO HTTP Request: POST http://localhost:11434/v1/chat/completions "HTTP/1.1 200 OK"
02:26:48,981 graphrag.llm.base.rate_limiting_llm INFO perf - llm.chat "create_community_report" with 0 retries took 84.0. input_tokens=4100, output_tokens=754
02:26:49,99 datashaper.workflow.workflow INFO executing verb window
02:26:49,103 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_community_reports.parquet
02:26:49,415 graphrag.index.run.workflow INFO dependencies for create_final_text_units: ['join_text_units_to_relationship_ids', 'join_text_units_to_entity_ids', 'create_base_text_units']
02:26:49,415 graphrag.utils.storage INFO read table from storage: join_text_units_to_relationship_ids.parquet
02:26:49,422 graphrag.utils.storage INFO read table from storage: join_text_units_to_entity_ids.parquet
02:26:49,427 graphrag.utils.storage INFO read table from storage: create_base_text_units.parquet
02:26:49,553 datashaper.workflow.workflow INFO executing verb select
02:26:49,597 datashaper.workflow.workflow INFO executing verb rename
02:26:49,641 datashaper.workflow.workflow INFO executing verb join
02:26:49,694 datashaper.workflow.workflow INFO executing verb join
02:26:49,748 datashaper.workflow.workflow INFO executing verb aggregate_override
02:26:49,916 datashaper.workflow.workflow INFO executing verb select
02:26:49,920 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_text_units.parquet
02:26:50,281 graphrag.index.run.workflow INFO dependencies for create_base_documents: ['create_final_text_units']
02:26:50,282 graphrag.utils.storage INFO read table from storage: create_final_text_units.parquet
02:26:50,382 datashaper.workflow.workflow INFO executing verb unroll
02:26:50,432 datashaper.workflow.workflow INFO executing verb select
02:26:50,481 datashaper.workflow.workflow INFO executing verb rename
02:26:50,531 datashaper.workflow.workflow INFO executing verb join
02:26:50,587 datashaper.workflow.workflow INFO executing verb aggregate_override
02:26:50,639 datashaper.workflow.workflow INFO executing verb join
02:26:50,708 datashaper.workflow.workflow INFO executing verb rename
02:26:50,773 datashaper.workflow.workflow INFO executing verb convert
02:26:50,951 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_base_documents.parquet
02:26:51,243 graphrag.index.run.workflow INFO dependencies for create_final_documents: ['create_base_documents']
02:26:51,244 graphrag.utils.storage INFO read table from storage: create_base_documents.parquet
02:26:51,353 datashaper.workflow.workflow INFO executing verb rename
02:26:51,356 graphrag.index.emit.parquet_table_emitter INFO emitting parquet table create_final_documents.parquet
02:26:51,559 graphrag.index.cli INFO All workflows completed successfully.
